{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Learning Basics\n",
    "In this module, you'll be acquiring and handling datasets. You will be using the Cinema Data, Salary Data and Reviews Data for the tasks in this module. <br> <br>\n",
    "**Pipeline:**\n",
    "* Acquiring the data\n",
    "* Handling files and formats\n",
    "* Data Analysis\n",
    "* Prediction\n",
    "* Analysing results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 1 - Data Acquisition\n",
    "* Retrieve the CinemaData dataset from Firebase, convert it to a CSV and save it in the 'Data' folder as 'CinemaData.csv'. You may use shell scripts, other packages and any other resources you require to do this. The database can be accessed with a HTTP request, ask a TA for the link. <br> \n",
    "* Using `wget`, download the 'SalaryData.txt' and save it in the 'Data' folder. Convert it to a CSV named 'SalaryData.csv' and save it in the same folder. It is avaliable at this link: <br>\n",
    "http://rebrand.ly/ml_salarydata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataframe = pd.read_csv('Data\\salary_data.txt',sep=' ')\n",
    "# dataframe.to_csv('Data\\salary_data.csv')\n",
    "# dataframe\n",
    "f = open('Data/CinemaData.json',)\n",
    "json_data = json.load(f)\n",
    "dataframe = pd.json_normalize(json_data)\n",
    "dataframe.to_csv('Data/CinemaData.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 2 - Dataset Handling\n",
    "\n",
    "* You can find the Reviews Data in a RAR file in the 'Data' directory. Extract this dataset and use it for this module.\n",
    "\n",
    "* The dataset contains positive and negative movie reviews. The files 'Positive_Reviews.txt' and 'Negative_Reviews.txt' contain names of files having positive and negative reviews respectively. Create two directories ‘pos’ and ‘neg’, and segregate the reviews accordingly into the two directories.\n",
    "\n",
    "* Load ‘cv000_29590.csv’ and report the number of words present in the first column.\n",
    "\n",
    "* Find the number of unique words in the first column. For this task, ignore punctuations, that is, punctuations are not considered as a word or a part of it.\n",
    "\n",
    "* Lookups: OS module, String functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-48-b654a1ce7e68>:2: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support regex separators (separators > 1 char and different from '\\s+' are interpreted as regex); you can avoid this warning by specifying engine='python'.\n",
      "  pos = list(pd.read_csv('Data/Positive_Reviews.txt', delimiter = \"', '\"))\n",
      "<ipython-input-48-b654a1ce7e68>:3: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support regex separators (separators > 1 char and different from '\\s+' are interpreted as regex); you can avoid this warning by specifying engine='python'.\n",
      "  neg = list(pd.read_csv('Data/Negative_Reviews.txt', delimiter = \"', '\"))\n"
     ]
    }
   ],
   "source": [
    "import shutil, os\n",
    "# pos = list(pd.read_csv('Data/Positive_Reviews.txt', delimiter = \"', '\"))\n",
    "# neg = list(pd.read_csv('Data/Negative_Reviews.txt', delimiter = \"', '\"))\n",
    "# for f in pos:\n",
    "#     shutil.move('Data/Reviews/'+f, 'Data/pos/'+f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "can only concatenate str (not \"int\") to str",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-77-f98e01f02134>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      9\u001b[0m     \u001b[0mall_words\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mword\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'\"'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m''\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m' '\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[0mall_words\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m!=\u001b[0m\u001b[1;34m''\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mall_words\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Number of words in 1st column:\"\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mall_words\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     12\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Number of words in 1st column:\"\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mall_words\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: can only concatenate str (not \"int\") to str"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv('Data/pos/cv000_29590.txt')\n",
    "punc =\"!.('):\\,/-?_\"\n",
    "words = data.iloc[:,0].tolist()\n",
    "all_words=[]\n",
    "x=''\n",
    "for word in words:\n",
    "    for letter in punc:\n",
    "        word = word.replace(letter,'')\n",
    "    all_words.extend(word.replace('\"','').split(' '))\n",
    "all_words = list(filter(lambda x:x!='',all_words))\n",
    "print(\"Number of words in 1st column:\"+len(all_words))\n",
    "print(\"Number of words in 1st column:\"+len(set(all_words)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
